# AI-Based Anomaly Detection System for HDFS Logs

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abdulwaheedal/AI_Anamoly_Detection_using_logs/blob/main/Anomaly_Detection_System_HDFS.ipynb)

An unsupervised machine learning system for detecting anomalies in HDFS logs using Drain3 log parsing and Isolation Forest with dynamic threshold optimization.

## üéØ Project Highlights

- **F1-Score**: 71.59%
- **Recall**: 81.14% (catches 81% of all anomalies)  
- **Precision**: 64.06%
- **11.1M logs** processed ‚Üí **45 templates** ‚Üí **575K blocks** analyzed

## üì• Dataset Download

**You need to download the dataset before running the notebook:**

1. **HDFS Dataset** (1.47 GB):
   - Download: [https://zenodo.org/record/3227177/files/HDFS_1.tar.gz](https://zenodo.org/record/3227177/files/HDFS_1.tar.gz)
   - Source: [LogHub Repository](https://github.com/logpai/loghub)

2. The notebook will automatically extract and process the files

**Note**: All output files (CSVs, PNGs, reports) will be generated when you run the notebook.

## üöÄ Quick Start

### Option 1: Google Colab (Recommended)

1. Click the "Open in Colab" badge above
2. The notebook will automatically download the dataset for you
3. Run all cells sequentially
4. All outputs will be generated in Colab's file system

### Option 2: Local Setup

1. **Clone this repository:**
```bash
   git clone https://github.com/abdulwaheedal/AI_Anamoly_Detection_using_logs.git
   cd AI_Anamoly_Detection_using_logs
```

2. **Install dependencies:**
```bash
   pip install -r requirements.txt
```

3. **Download the dataset manually:**
```bash
   wget https://zenodo.org/record/3227177/files/HDFS_1.tar.gz
   tar -xvf HDFS_1.tar.gz
```

4. **Run the notebook:**
```bash
   jupyter notebook Anomaly_Detection_System_HDFS.ipynb
```

## üìä What This Repository Contains
```
Anomaly_Detection_System_HDFS/
‚îú‚îÄ‚îÄ README.md                              # This file
‚îú‚îÄ‚îÄ requirements.txt                       # Python dependencies
‚îú‚îÄ‚îÄ Anomaly_Detection_System_HDFS.ipynb    # Main notebook (THE CODE)
‚îî‚îÄ‚îÄ .gitignore
```

**What's NOT included (generated when you run the notebook):**
- `HDFS.log` - Downloaded from Zenodo
- `anomaly_label.csv` - Extracted from dataset
- `parsed_logs.csv` - Generated by Drain3
- `block_features.csv` - Generated feature matrix
- `anomaly_detection_results_optimized.csv` - Model predictions
- `pca_visualization_complete.png` - PCA visualization
- `precision_recall_analysis.png` - Threshold optimization plot
- `PROJECT_REPORT.txt` - Comprehensive report

All of these will be created automatically when you run the notebook!

## üõ†Ô∏è Technologies Used

- **Drain3** - Log parsing and template extraction
- **Scikit-learn** - Isolation Forest, TF-IDF, PCA
- **Pandas & NumPy** - Data manipulation
- **Matplotlib** - Visualizations

## üìù Methodology

1. **Log Parsing**: Drain3 algorithm extracts 45 templates from 11M+ raw logs
2. **Feature Engineering**: TF-IDF vectorization creates 475-dimensional feature space
3. **Anomaly Detection**: Isolation Forest with dynamic threshold optimization
4. **Visualization**: PCA dimensionality reduction for interpretability

## üìà Performance Metrics

| Metric | Value |
|--------|-------|
| F1-Score | 71.59% |
| Precision | 64.06% |
| Recall | 81.14% |
| Accuracy | 98.11% |

**Key Innovation**: Dynamic threshold optimization using Precision-Recall curve analysis provides 15-20% better performance than fixed contamination approaches.

## üéì Use Cases

- System log monitoring
- Distributed system health checks
- Predictive maintenance
- Security threat detection

## üìö References

- [Drain3 GitHub](https://github.com/logpai/Drain3)
- [LogHub Dataset](https://github.com/logpai/loghub)
- [Isolation Forest Paper](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)

## üìß Contact

For questions, please open an issue in this repository or DM me here[<img src="https://badgen.net" />](https://x.com/faaa1z)

---

**Note**: This project demonstrates production-grade log analysis. The notebook is self-contained and will download/generate all necessary files when executed.
